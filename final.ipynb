{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKY9MvIa7Gjs"
      },
      "source": [
        "#Importing libraries and dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "HRFEcH3i7SCv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import gridspec\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AfuhvF_y-8hl",
        "outputId": "2b1ca399-815b-4460-a5b6-d888a64ef66e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "#loading the dataset to pandas dataframe\n",
        "credit_card_data=pd.read_csv('/content/drive/MyDrive/ML LAB/creditcard.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "xEZ2KH5N_Mg3",
        "outputId": "fa933f13-bd7e-46a9-e434-be3647a1725f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
              "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
              "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
              "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
              "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
              "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
              "\n",
              "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
              "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
              "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
              "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
              "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
              "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
              "\n",
              "        V26       V27       V28  Amount  Class  \n",
              "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
              "1  0.125895 -0.008983  0.014724    2.69      0  \n",
              "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
              "3 -0.221929  0.062723  0.061458  123.50      0  \n",
              "4  0.502292  0.219422  0.215153   69.99      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a63b6d27-4db4-4859-8f42-d38b6c205a02\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>149.62</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>2.69</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>378.66</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>123.50</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.0</td>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>69.99</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a63b6d27-4db4-4859-8f42-d38b6c205a02')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a63b6d27-4db4-4859-8f42-d38b6c205a02 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a63b6d27-4db4-4859-8f42-d38b6c205a02');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#first five rows of the dataset\n",
        "credit_card_data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "Nb7oH_UrAOZa",
        "outputId": "6fed007d-4756-4e10-eb3f-c2c871133be6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            Time         V1         V2        V3        V4        V5  \\\n",
              "284802  172786.0 -11.881118  10.071785 -9.834783 -2.066656 -5.364473   \n",
              "284803  172787.0  -0.732789  -0.055080  2.035030 -0.738589  0.868229   \n",
              "284804  172788.0   1.919565  -0.301254 -3.249640 -0.557828  2.630515   \n",
              "284805  172788.0  -0.240440   0.530483  0.702510  0.689799 -0.377961   \n",
              "284806  172792.0  -0.533413  -0.189733  0.703337 -0.506271 -0.012546   \n",
              "\n",
              "              V6        V7        V8        V9  ...       V21       V22  \\\n",
              "284802 -2.606837 -4.918215  7.305334  1.914428  ...  0.213454  0.111864   \n",
              "284803  1.058415  0.024330  0.294869  0.584800  ...  0.214205  0.924384   \n",
              "284804  3.031260 -0.296827  0.708417  0.432454  ...  0.232045  0.578229   \n",
              "284805  0.623708 -0.686180  0.679145  0.392087  ...  0.265245  0.800049   \n",
              "284806 -0.649617  1.577006 -0.414650  0.486180  ...  0.261057  0.643078   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28  Amount  \\\n",
              "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731    0.77   \n",
              "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527   24.79   \n",
              "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561   67.88   \n",
              "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533   10.00   \n",
              "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649  217.00   \n",
              "\n",
              "        Class  \n",
              "284802      0  \n",
              "284803      0  \n",
              "284804      0  \n",
              "284805      0  \n",
              "284806      0  \n",
              "\n",
              "[5 rows x 31 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f88724f6-8abf-4dfc-9c29-2a2be2579636\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Time</th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Amount</th>\n",
              "      <th>Class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>172786.0</td>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0.77</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>172787.0</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>24.79</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>67.88</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>172788.0</td>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>10.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>172792.0</td>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>...</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>217.00</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 31 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f88724f6-8abf-4dfc-9c29-2a2be2579636')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f88724f6-8abf-4dfc-9c29-2a2be2579636 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f88724f6-8abf-4dfc-9c29-2a2be2579636');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "credit_card_data.tail()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sobVu2wfAe8h",
        "outputId": "f6ac379c-9020-4a02-b079-f898c5700876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 284807 entries, 0 to 284806\n",
            "Data columns (total 31 columns):\n",
            " #   Column  Non-Null Count   Dtype  \n",
            "---  ------  --------------   -----  \n",
            " 0   Time    284807 non-null  float64\n",
            " 1   V1      284807 non-null  float64\n",
            " 2   V2      284807 non-null  float64\n",
            " 3   V3      284807 non-null  float64\n",
            " 4   V4      284807 non-null  float64\n",
            " 5   V5      284807 non-null  float64\n",
            " 6   V6      284807 non-null  float64\n",
            " 7   V7      284807 non-null  float64\n",
            " 8   V8      284807 non-null  float64\n",
            " 9   V9      284807 non-null  float64\n",
            " 10  V10     284807 non-null  float64\n",
            " 11  V11     284807 non-null  float64\n",
            " 12  V12     284807 non-null  float64\n",
            " 13  V13     284807 non-null  float64\n",
            " 14  V14     284807 non-null  float64\n",
            " 15  V15     284807 non-null  float64\n",
            " 16  V16     284807 non-null  float64\n",
            " 17  V17     284807 non-null  float64\n",
            " 18  V18     284807 non-null  float64\n",
            " 19  V19     284807 non-null  float64\n",
            " 20  V20     284807 non-null  float64\n",
            " 21  V21     284807 non-null  float64\n",
            " 22  V22     284807 non-null  float64\n",
            " 23  V23     284807 non-null  float64\n",
            " 24  V24     284807 non-null  float64\n",
            " 25  V25     284807 non-null  float64\n",
            " 26  V26     284807 non-null  float64\n",
            " 27  V27     284807 non-null  float64\n",
            " 28  V28     284807 non-null  float64\n",
            " 29  Amount  284807 non-null  float64\n",
            " 30  Class   284807 non-null  int64  \n",
            "dtypes: float64(30), int64(1)\n",
            "memory usage: 67.4 MB\n"
          ]
        }
      ],
      "source": [
        "#dataset information\n",
        "credit_card_data.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NQW8hY6OBI4C",
        "outputId": "90a93a59-07b3-4e99-d12c-b559023a38fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Time      0\n",
              "V1        0\n",
              "V2        0\n",
              "V3        0\n",
              "V4        0\n",
              "V5        0\n",
              "V6        0\n",
              "V7        0\n",
              "V8        0\n",
              "V9        0\n",
              "V10       0\n",
              "V11       0\n",
              "V12       0\n",
              "V13       0\n",
              "V14       0\n",
              "V15       0\n",
              "V16       0\n",
              "V17       0\n",
              "V18       0\n",
              "V19       0\n",
              "V20       0\n",
              "V21       0\n",
              "V22       0\n",
              "V23       0\n",
              "V24       0\n",
              "V25       0\n",
              "V26       0\n",
              "V27       0\n",
              "V28       0\n",
              "Amount    0\n",
              "Class     0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#checking the number of missing values in each column\n",
        "credit_card_data.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " If a feature has a variance that is orders of magnitude larger than others, it might dominate the objective function and make the estimator unable to learn from other features correctly as expected."
      ],
      "metadata": {
        "id": "yKKghgerjq1Q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 483
        },
        "id": "sSv37nf67O1m",
        "outputId": "d2e0f92e-83b9-4c0d-e6e0-5812eda79442"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "               V1         V2        V3        V4        V5        V6  \\\n",
              "0       -1.359807  -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
              "1        1.191857   0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
              "2       -1.358354  -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
              "3       -0.966272  -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
              "4       -1.158233   0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
              "...           ...        ...       ...       ...       ...       ...   \n",
              "284802 -11.881118  10.071785 -9.834783 -2.066656 -5.364473 -2.606837   \n",
              "284803  -0.732789  -0.055080  2.035030 -0.738589  0.868229  1.058415   \n",
              "284804   1.919565  -0.301254 -3.249640 -0.557828  2.630515  3.031260   \n",
              "284805  -0.240440   0.530483  0.702510  0.689799 -0.377961  0.623708   \n",
              "284806  -0.533413  -0.189733  0.703337 -0.506271 -0.012546 -0.649617   \n",
              "\n",
              "              V7        V8        V9       V10  ...       V21       V22  \\\n",
              "0       0.239599  0.098698  0.363787  0.090794  ... -0.018307  0.277838   \n",
              "1      -0.078803  0.085102 -0.255425 -0.166974  ... -0.225775 -0.638672   \n",
              "2       0.791461  0.247676 -1.514654  0.207643  ...  0.247998  0.771679   \n",
              "3       0.237609  0.377436 -1.387024 -0.054952  ... -0.108300  0.005274   \n",
              "4       0.592941 -0.270533  0.817739  0.753074  ... -0.009431  0.798278   \n",
              "...          ...       ...       ...       ...  ...       ...       ...   \n",
              "284802 -4.918215  7.305334  1.914428  4.356170  ...  0.213454  0.111864   \n",
              "284803  0.024330  0.294869  0.584800 -0.975926  ...  0.214205  0.924384   \n",
              "284804 -0.296827  0.708417  0.432454 -0.484782  ...  0.232045  0.578229   \n",
              "284805 -0.686180  0.679145  0.392087 -0.399126  ...  0.265245  0.800049   \n",
              "284806  1.577006 -0.414650  0.486180 -0.915427  ...  0.261057  0.643078   \n",
              "\n",
              "             V23       V24       V25       V26       V27       V28  Class  \\\n",
              "0      -0.110474  0.066928  0.128539 -0.189115  0.133558 -0.021053      0   \n",
              "1       0.101288 -0.339846  0.167170  0.125895 -0.008983  0.014724      0   \n",
              "2       0.909412 -0.689281 -0.327642 -0.139097 -0.055353 -0.059752      0   \n",
              "3      -0.190321 -1.175575  0.647376 -0.221929  0.062723  0.061458      0   \n",
              "4      -0.137458  0.141267 -0.206010  0.502292  0.219422  0.215153      0   \n",
              "...          ...       ...       ...       ...       ...       ...    ...   \n",
              "284802  1.014480 -0.509348  1.436807  0.250034  0.943651  0.823731      0   \n",
              "284803  0.012463 -1.016226 -0.606624 -0.395255  0.068472 -0.053527      0   \n",
              "284804 -0.037501  0.640134  0.265745 -0.087371  0.004455 -0.026561      0   \n",
              "284805 -0.163298  0.123205 -0.569159  0.546668  0.108821  0.104533      0   \n",
              "284806  0.376777  0.008797 -0.473649 -0.818267 -0.002415  0.013649      0   \n",
              "\n",
              "        normAmount  \n",
              "0         0.244964  \n",
              "1        -0.342475  \n",
              "2         1.160686  \n",
              "3         0.140534  \n",
              "4        -0.073403  \n",
              "...            ...  \n",
              "284802   -0.350151  \n",
              "284803   -0.254117  \n",
              "284804   -0.081839  \n",
              "284805   -0.313249  \n",
              "284806    0.514355  \n",
              "\n",
              "[284315 rows x 30 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-def8e1f0-de98-487b-b381-84a666babe47\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>Class</th>\n",
              "      <th>normAmount</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.359807</td>\n",
              "      <td>-0.072781</td>\n",
              "      <td>2.536347</td>\n",
              "      <td>1.378155</td>\n",
              "      <td>-0.338321</td>\n",
              "      <td>0.462388</td>\n",
              "      <td>0.239599</td>\n",
              "      <td>0.098698</td>\n",
              "      <td>0.363787</td>\n",
              "      <td>0.090794</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.018307</td>\n",
              "      <td>0.277838</td>\n",
              "      <td>-0.110474</td>\n",
              "      <td>0.066928</td>\n",
              "      <td>0.128539</td>\n",
              "      <td>-0.189115</td>\n",
              "      <td>0.133558</td>\n",
              "      <td>-0.021053</td>\n",
              "      <td>0</td>\n",
              "      <td>0.244964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.191857</td>\n",
              "      <td>0.266151</td>\n",
              "      <td>0.166480</td>\n",
              "      <td>0.448154</td>\n",
              "      <td>0.060018</td>\n",
              "      <td>-0.082361</td>\n",
              "      <td>-0.078803</td>\n",
              "      <td>0.085102</td>\n",
              "      <td>-0.255425</td>\n",
              "      <td>-0.166974</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.225775</td>\n",
              "      <td>-0.638672</td>\n",
              "      <td>0.101288</td>\n",
              "      <td>-0.339846</td>\n",
              "      <td>0.167170</td>\n",
              "      <td>0.125895</td>\n",
              "      <td>-0.008983</td>\n",
              "      <td>0.014724</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.342475</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-1.358354</td>\n",
              "      <td>-1.340163</td>\n",
              "      <td>1.773209</td>\n",
              "      <td>0.379780</td>\n",
              "      <td>-0.503198</td>\n",
              "      <td>1.800499</td>\n",
              "      <td>0.791461</td>\n",
              "      <td>0.247676</td>\n",
              "      <td>-1.514654</td>\n",
              "      <td>0.207643</td>\n",
              "      <td>...</td>\n",
              "      <td>0.247998</td>\n",
              "      <td>0.771679</td>\n",
              "      <td>0.909412</td>\n",
              "      <td>-0.689281</td>\n",
              "      <td>-0.327642</td>\n",
              "      <td>-0.139097</td>\n",
              "      <td>-0.055353</td>\n",
              "      <td>-0.059752</td>\n",
              "      <td>0</td>\n",
              "      <td>1.160686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.966272</td>\n",
              "      <td>-0.185226</td>\n",
              "      <td>1.792993</td>\n",
              "      <td>-0.863291</td>\n",
              "      <td>-0.010309</td>\n",
              "      <td>1.247203</td>\n",
              "      <td>0.237609</td>\n",
              "      <td>0.377436</td>\n",
              "      <td>-1.387024</td>\n",
              "      <td>-0.054952</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.108300</td>\n",
              "      <td>0.005274</td>\n",
              "      <td>-0.190321</td>\n",
              "      <td>-1.175575</td>\n",
              "      <td>0.647376</td>\n",
              "      <td>-0.221929</td>\n",
              "      <td>0.062723</td>\n",
              "      <td>0.061458</td>\n",
              "      <td>0</td>\n",
              "      <td>0.140534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-1.158233</td>\n",
              "      <td>0.877737</td>\n",
              "      <td>1.548718</td>\n",
              "      <td>0.403034</td>\n",
              "      <td>-0.407193</td>\n",
              "      <td>0.095921</td>\n",
              "      <td>0.592941</td>\n",
              "      <td>-0.270533</td>\n",
              "      <td>0.817739</td>\n",
              "      <td>0.753074</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.009431</td>\n",
              "      <td>0.798278</td>\n",
              "      <td>-0.137458</td>\n",
              "      <td>0.141267</td>\n",
              "      <td>-0.206010</td>\n",
              "      <td>0.502292</td>\n",
              "      <td>0.219422</td>\n",
              "      <td>0.215153</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.073403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284802</th>\n",
              "      <td>-11.881118</td>\n",
              "      <td>10.071785</td>\n",
              "      <td>-9.834783</td>\n",
              "      <td>-2.066656</td>\n",
              "      <td>-5.364473</td>\n",
              "      <td>-2.606837</td>\n",
              "      <td>-4.918215</td>\n",
              "      <td>7.305334</td>\n",
              "      <td>1.914428</td>\n",
              "      <td>4.356170</td>\n",
              "      <td>...</td>\n",
              "      <td>0.213454</td>\n",
              "      <td>0.111864</td>\n",
              "      <td>1.014480</td>\n",
              "      <td>-0.509348</td>\n",
              "      <td>1.436807</td>\n",
              "      <td>0.250034</td>\n",
              "      <td>0.943651</td>\n",
              "      <td>0.823731</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.350151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284803</th>\n",
              "      <td>-0.732789</td>\n",
              "      <td>-0.055080</td>\n",
              "      <td>2.035030</td>\n",
              "      <td>-0.738589</td>\n",
              "      <td>0.868229</td>\n",
              "      <td>1.058415</td>\n",
              "      <td>0.024330</td>\n",
              "      <td>0.294869</td>\n",
              "      <td>0.584800</td>\n",
              "      <td>-0.975926</td>\n",
              "      <td>...</td>\n",
              "      <td>0.214205</td>\n",
              "      <td>0.924384</td>\n",
              "      <td>0.012463</td>\n",
              "      <td>-1.016226</td>\n",
              "      <td>-0.606624</td>\n",
              "      <td>-0.395255</td>\n",
              "      <td>0.068472</td>\n",
              "      <td>-0.053527</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.254117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284804</th>\n",
              "      <td>1.919565</td>\n",
              "      <td>-0.301254</td>\n",
              "      <td>-3.249640</td>\n",
              "      <td>-0.557828</td>\n",
              "      <td>2.630515</td>\n",
              "      <td>3.031260</td>\n",
              "      <td>-0.296827</td>\n",
              "      <td>0.708417</td>\n",
              "      <td>0.432454</td>\n",
              "      <td>-0.484782</td>\n",
              "      <td>...</td>\n",
              "      <td>0.232045</td>\n",
              "      <td>0.578229</td>\n",
              "      <td>-0.037501</td>\n",
              "      <td>0.640134</td>\n",
              "      <td>0.265745</td>\n",
              "      <td>-0.087371</td>\n",
              "      <td>0.004455</td>\n",
              "      <td>-0.026561</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.081839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284805</th>\n",
              "      <td>-0.240440</td>\n",
              "      <td>0.530483</td>\n",
              "      <td>0.702510</td>\n",
              "      <td>0.689799</td>\n",
              "      <td>-0.377961</td>\n",
              "      <td>0.623708</td>\n",
              "      <td>-0.686180</td>\n",
              "      <td>0.679145</td>\n",
              "      <td>0.392087</td>\n",
              "      <td>-0.399126</td>\n",
              "      <td>...</td>\n",
              "      <td>0.265245</td>\n",
              "      <td>0.800049</td>\n",
              "      <td>-0.163298</td>\n",
              "      <td>0.123205</td>\n",
              "      <td>-0.569159</td>\n",
              "      <td>0.546668</td>\n",
              "      <td>0.108821</td>\n",
              "      <td>0.104533</td>\n",
              "      <td>0</td>\n",
              "      <td>-0.313249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284806</th>\n",
              "      <td>-0.533413</td>\n",
              "      <td>-0.189733</td>\n",
              "      <td>0.703337</td>\n",
              "      <td>-0.506271</td>\n",
              "      <td>-0.012546</td>\n",
              "      <td>-0.649617</td>\n",
              "      <td>1.577006</td>\n",
              "      <td>-0.414650</td>\n",
              "      <td>0.486180</td>\n",
              "      <td>-0.915427</td>\n",
              "      <td>...</td>\n",
              "      <td>0.261057</td>\n",
              "      <td>0.643078</td>\n",
              "      <td>0.376777</td>\n",
              "      <td>0.008797</td>\n",
              "      <td>-0.473649</td>\n",
              "      <td>-0.818267</td>\n",
              "      <td>-0.002415</td>\n",
              "      <td>0.013649</td>\n",
              "      <td>0</td>\n",
              "      <td>0.514355</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>284315 rows × 30 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-def8e1f0-de98-487b-b381-84a666babe47')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-def8e1f0-de98-487b-b381-84a666babe47 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-def8e1f0-de98-487b-b381-84a666babe47');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "credit_card_data['normAmount'] = StandardScaler().fit_transform(credit_card_data['Amount'].values.reshape(-1, 1))\n",
        "data = credit_card_data.drop(['Time','Amount'],axis=1)\n",
        "#class 1 data present in data set\n",
        "data[data.Class==1]\n",
        "data[data.Class==0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jsId4yp4W2R"
      },
      "source": [
        "#Checking the Target Class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRpdhpBfBjEs",
        "outputId": "f8112e92-0121-47aa-a208-767132e435c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    284315\n",
              "1       492\n",
              "Name: Class, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#distribution of legit transaction and fraud transaction\n",
        "credit_card_data['Class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "rfSJYH2F4bah",
        "outputId": "4f16b6d1-2119-47ae-acc7-d0d229742270"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f15fb1e80d0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "sns.countplot(x='Class', data=credit_card_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdZu_6gFGR4V"
      },
      "source": [
        "This dataset is highly unbalanced"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JEGQZklWGXnt"
      },
      "source": [
        "0 --> Normal Transaction\n",
        "\n",
        "1 --> Fraudulent transaction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGlBv3sS42KT"
      },
      "source": [
        "This is a clear example where using a typical accuracy score to evaluate our classification algorithm. For example, if we just used a majority class to assign values to all records, we will still be having a high accuracy, BUT WE WOULD BE CLASSIFYING ALL \"1\" INCORRECTLY!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XssXGmqL54En"
      },
      "source": [
        "#Resampling the dataset\n",
        "\n",
        "Essentially this is a method that will process the data to have an approximate 50-50 ratio.\n",
        "\n",
        "One way to achieve this is by OVER-sampling, which is adding copies of the under-represented class (better when you have little data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "7FaGhfuA9eix"
      },
      "outputs": [],
      "source": [
        "X = data.loc[:, data.columns != 'Class']\n",
        "y = data.loc[:, data.columns == 'Class']\n",
        "#print(y.sum())\n",
        "# print(X)\n",
        "#shows y dataset is of column class which has both 0 and 1\n",
        "# y[y.Class==1]\n",
        "# y[y.Class==0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5hw6iiB80G7"
      },
      "source": [
        "#Applying SMOTE with Over Sampling\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWfRfUg285JV"
      },
      "source": [
        "As we mentioned earlier, there are several ways to resample skewed data. Apart from under and over sampling, there is a very popular approach called SMOTE (Synthetic Minority Over-Sampling Technique), which is a combination of oversampling and undersampling, but the oversampling approach is not by replicating minority class but constructing new minority class data instance via an algorithm."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gka6glaf8VAi",
        "outputId": "d4bb0af7-06d3-4f14-f846-2ce84d6da722"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Percentage of fraud counts in original dataset:0.1727485630620034%\n",
            "Percentage of fraud counts in the new data:50.0%\n"
          ]
        }
      ],
      "source": [
        "from imblearn.over_sampling import SMOTE \n",
        "#Over sampling\n",
        "sm = SMOTE(random_state=42, sampling_strategy='auto')\n",
        "\n",
        "X_sampled,y_sampled = sm.fit_resample(X,y)\n",
        "\n",
        "#Percentage of fraudlent records in original data\n",
        "Source_data_no_fraud_count = len(data[data.Class==0])\n",
        "Source_data_fraud_count = len(data[data.Class==1])\n",
        "print('Percentage of fraud counts in original dataset:{}%'.format((Source_data_fraud_count*100)/(Source_data_no_fraud_count+Source_data_fraud_count)))\n",
        "\n",
        "#Percentage of fraudlent records in sampled data\n",
        "Sampled_data_no_fraud_count = len(y_sampled[y_sampled==0])\n",
        "Sampled_data_fraud_count = len(y_sampled[y_sampled==1])\n",
        "print('Percentage of fraud counts in the new data:{}%'.format((Sampled_data_fraud_count*100)/(Sampled_data_no_fraud_count+Sampled_data_fraud_count)))\n",
        "# X_sampled.head(5)\n",
        "# print(y_sampled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "trvsqUChNlmt"
      },
      "source": [
        "#Split the data into trainning data and testing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TGl1VDjtMSe3",
        "outputId": "56af7317-08df-43fa-c731-6728c81ea630"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number transactions train dataset:  199364\n",
            "Number transactions test dataset:  85443\n",
            "Total number of transactions:  284807\n"
          ]
        }
      ],
      "source": [
        "# Whole dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = 5)\n",
        "\n",
        "print(\"Number transactions train dataset: \", len(X_train))\n",
        "print(\"Number transactions test dataset: \", len(X_test))\n",
        "print(\"Total number of transactions: \", len(X_train)+len(X_test))\n",
        "\n",
        "# #both ytrain n ytest have 0 & 1 class\n",
        "# print(y_train.shape)\n",
        "# print(y_train[y_train.Class==1])\n",
        "# print(y_train[y_train.Class==0])\n",
        "# print(y_test.shape)\n",
        "# print(y_test[y_test.Class==1])\n",
        "# print(y_test[y_test.Class==0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "kp6N9bhVumTb"
      },
      "outputs": [],
      "source": [
        "X_train_sample, X_test_sample, y_train_sample, y_test_sample = train_test_split(X_sampled ,y_sampled ,test_size = 0.2  ,random_state = 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4GhA_50_jLA",
        "outputId": "714be80b-6100-42bb-d110-8645b01ee70d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Number transactions train dataset:  79608\n",
            "Number transactions test dataset:  34118\n",
            "Total number of transactions:  113726\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# oversampled dataset\n",
        "X_train_sampled, X_test_sampled, y_train_sampled, y_test_sampled = train_test_split(X_test_sample ,y_test_sample ,test_size = 0.3  ,random_state = 5)\n",
        "print(\"\")\n",
        "print(\"Number transactions train dataset: \", len(X_train_sampled))\n",
        "print(\"Number transactions test dataset: \", len(X_test_sampled))\n",
        "print(\"Total number of transactions: \", len(X_train_sampled)+len(X_test_sampled))\n",
        "\n",
        "\n",
        "# X_train_sampled_df = pd.DataFrame(X_train_sampled)\n",
        "# y_train_sampled_df = pd.DataFrame(y_train_sampled)\n",
        "# X_test_sampled_df = pd.DataFrame(X_test_sampled)\n",
        "# y_test_sampled_df = pd.DataFrame(y_test_sampled)\n",
        "# X_train_sampled_df.head(10)\n",
        "# y_train_sampled_df.head(10)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cG04ooo7D2NC"
      },
      "source": [
        "Recall score is the metric that will help us try to capture the most fraudulent transactions. Accuracy, Precision and Recall work for a confusion matrix\n",
        "\n",
        "Accuracy = (TP+TN)/total\n",
        "Precision = TP/(TP+FP)\n",
        "Recall = TP/(TP+FN)\n",
        "\n",
        "As we know, due to the imbalacing of the data, many observations could be predicted as False Negatives, being, that we predict a normal transaction, but it is in fact a fraudulent one. Recall captures this.\n",
        "\n",
        "Obviously, trying to increase recall, tends to come with a decrease of precision. However, in our case, if we predict that a transaction is fraudulent and turns out not to be, is not a massive problem compared to the opposite.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aQt_hKOeGuZ"
      },
      "source": [
        "#Model Training\n",
        "\n",
        "#Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "z001pHzwD87R"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix,precision_recall_curve,auc,roc_auc_score,roc_curve,recall_score,classification_report,accuracy_score,precision_score,f1_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omQZuIMxGgSS"
      },
      "source": [
        "#HYPERTUNING FUNCTION\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "ATrCVZYke6ey"
      },
      "outputs": [],
      "source": [
        "def logistic_regression(x_train,x_test,y_train,y_test):\n",
        "  c_param_range = [0.01,0.1,1,10,100]\n",
        "  solver=[\"lbfgs\", \"liblinear\", \"sag\", \"saga\"]\n",
        "  penaltys={ \"lbfgs\":  ['l2'] , \"liblinear\":['l1', 'l2'] , \"sag\":['l2'], \"saga\": [ \"l1\", \"l2\"] }\n",
        "  li=list()\n",
        "  cval=None \n",
        "  sol=None \n",
        "  pen=None\n",
        "  rec_max=0\n",
        "  for solve in solver: \n",
        "    for penalty in penaltys[solve]:\n",
        "      for c in c_param_range:\n",
        "        lr = LogisticRegression(C = c, penalty = penalty ,solver=solve  )\n",
        "        lr.fit(x_train,y_train)\n",
        "        y_pred=lr.predict(x_test)\n",
        "        recall=recall_score(y_test,y_pred)\n",
        "        accuracy=accuracy_score(y_test,y_pred)\n",
        "        precision=precision_score(y_test,y_pred)\n",
        "        f1score=f1_score(y_test,y_pred)\n",
        "\n",
        "        classification =(classification_report(y_test, y_pred))\n",
        "        li.append([solve,penalty,c,recall,accuracy,precision,f1score])\n",
        "        if recall>rec_max:\n",
        "          cval=c\n",
        "          sol=solve\n",
        "          pen=penalty\n",
        "          rec_max=recall\n",
        "\n",
        "  \n",
        "  print(\"Maximum Values Obtained at : \")\n",
        "  print(\"Solver =\",sol)\n",
        "  print(\"Penalty =\",pen)\n",
        "  print(\"C =\",cval)\n",
        "  print(\"Recall =\",rec_max)\n",
        "  return li \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-rhkz_49XU3"
      },
      "source": [
        "#Hypertuning on the original dataset\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "HC4HZXHoqHYs"
      },
      "outputs": [],
      "source": [
        "y_train=np.array(y_train).ravel()\n",
        "y_test=np.array(y_test).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mOJw4_QEpN5S",
        "outputId": "ef480549-3210-4685-8a06-7700c9b02329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Values Obtained at : \n",
            "Solver = lbfgs\n",
            "Penalty = l2\n",
            "C = 1\n",
            "Recall = 0.6081081081081081\n"
          ]
        }
      ],
      "source": [
        "li=logistic_regression(X_train, X_test, y_train, y_test)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1vx8eWgxDAd",
        "outputId": "5a95ec47-7e5f-4d17-d5de-9041d560cb30"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Solver Penalty       C  Recall Score  Accuracy  Precision  F1-Score\n",
            "0       lbfgs      l2    0.01      0.574324  0.999146   0.894737  0.699588\n",
            "1       lbfgs      l2    0.10      0.601351  0.999181   0.890000  0.717742\n",
            "2       lbfgs      l2    1.00      0.608108  0.999192   0.891089  0.722892\n",
            "3       lbfgs      l2   10.00      0.601351  0.999181   0.890000  0.717742\n",
            "4       lbfgs      l2  100.00      0.601351  0.999181   0.890000  0.717742\n",
            "5   liblinear      l1    0.01      0.547297  0.999111   0.900000  0.680672\n",
            "6   liblinear      l1    0.10      0.587838  0.999169   0.896907  0.710204\n",
            "7   liblinear      l1    1.00      0.608108  0.999192   0.891089  0.722892\n",
            "8   liblinear      l1   10.00      0.601351  0.999181   0.890000  0.717742\n",
            "9   liblinear      l1  100.00      0.601351  0.999181   0.890000  0.717742\n",
            "10  liblinear      l2    0.01      0.554054  0.999122   0.901099  0.686192\n",
            "11  liblinear      l2    0.10      0.567568  0.999134   0.893617  0.694215\n",
            "12  liblinear      l2    1.00      0.608108  0.999192   0.891089  0.722892\n",
            "13  liblinear      l2   10.00      0.601351  0.999181   0.890000  0.717742\n",
            "14  liblinear      l2  100.00      0.601351  0.999181   0.890000  0.717742\n",
            "15        sag      l2    0.01      0.560811  0.999134   0.902174  0.691667\n",
            "16        sag      l2    0.10      0.574324  0.999157   0.904255  0.702479\n",
            "17        sag      l2    1.00      0.574324  0.999157   0.904255  0.702479\n",
            "18        sag      l2   10.00      0.574324  0.999157   0.904255  0.702479\n",
            "19        sag      l2  100.00      0.574324  0.999157   0.904255  0.702479\n",
            "20       saga      l1    0.01      0.533784  0.999087   0.897727  0.669492\n",
            "21       saga      l1    0.10      0.567568  0.999146   0.903226  0.697095\n",
            "22       saga      l1    1.00      0.560811  0.999134   0.902174  0.691667\n",
            "23       saga      l1   10.00      0.560811  0.999134   0.902174  0.691667\n",
            "24       saga      l1  100.00      0.560811  0.999134   0.902174  0.691667\n",
            "25       saga      l2    0.01      0.554054  0.999122   0.901099  0.686192\n",
            "26       saga      l2    0.10      0.560811  0.999134   0.902174  0.691667\n",
            "27       saga      l2    1.00      0.560811  0.999134   0.902174  0.691667\n",
            "28       saga      l2   10.00      0.560811  0.999134   0.902174  0.691667\n",
            "29       saga      l2  100.00      0.560811  0.999134   0.902174  0.691667\n"
          ]
        }
      ],
      "source": [
        "df=pd.DataFrame(li,columns=[\"Solver\",\"Penalty\",\"C\",\"Recall Score\",\"Accuracy\",\"Precision\",\"F1-Score\"])\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4xfHs39f9bu3"
      },
      "source": [
        "#Hypertuning on the resampled dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "3nagqM55_6Dl"
      },
      "outputs": [],
      "source": [
        "y_train_sampled=np.array(y_train_sampled).ravel()\n",
        "y_test_sampled=np.array(y_test_sampled).ravel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tV8Bfp_n9fMY",
        "outputId": "9cf06bef-da0e-4008-c4b9-311ac9dc174d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum Values Obtained at : \n",
            "Solver = lbfgs\n",
            "Penalty = l2\n",
            "C = 100\n",
            "Recall = 0.9161949226728917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_sag.py:354: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  ConvergenceWarning,\n"
          ]
        }
      ],
      "source": [
        "li2=logistic_regression(X_train_sampled, X_test_sampled, y_train_sampled, y_test_sampled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y85mHE-s_F3_",
        "outputId": "ae2cc6bb-8a82-4f93-8594-000bd8fca571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Solver Penalty       C  Recall Score  Accuracy  Precision  F1-Score\n",
            "0       lbfgs      l2    0.01      0.574324  0.999146   0.894737  0.699588\n",
            "1       lbfgs      l2    0.10      0.601351  0.999181   0.890000  0.717742\n",
            "2       lbfgs      l2    1.00      0.608108  0.999192   0.891089  0.722892\n",
            "3       lbfgs      l2   10.00      0.601351  0.999181   0.890000  0.717742\n",
            "4       lbfgs      l2  100.00      0.601351  0.999181   0.890000  0.717742\n",
            "5   liblinear      l1    0.01      0.547297  0.999111   0.900000  0.680672\n",
            "6   liblinear      l1    0.10      0.587838  0.999169   0.896907  0.710204\n",
            "7   liblinear      l1    1.00      0.608108  0.999192   0.891089  0.722892\n",
            "8   liblinear      l1   10.00      0.601351  0.999181   0.890000  0.717742\n",
            "9   liblinear      l1  100.00      0.601351  0.999181   0.890000  0.717742\n",
            "10  liblinear      l2    0.01      0.554054  0.999122   0.901099  0.686192\n",
            "11  liblinear      l2    0.10      0.567568  0.999134   0.893617  0.694215\n",
            "12  liblinear      l2    1.00      0.608108  0.999192   0.891089  0.722892\n",
            "13  liblinear      l2   10.00      0.601351  0.999181   0.890000  0.717742\n",
            "14  liblinear      l2  100.00      0.601351  0.999181   0.890000  0.717742\n",
            "15        sag      l2    0.01      0.560811  0.999134   0.902174  0.691667\n",
            "16        sag      l2    0.10      0.574324  0.999157   0.904255  0.702479\n",
            "17        sag      l2    1.00      0.574324  0.999157   0.904255  0.702479\n",
            "18        sag      l2   10.00      0.574324  0.999157   0.904255  0.702479\n",
            "19        sag      l2  100.00      0.574324  0.999157   0.904255  0.702479\n",
            "20       saga      l1    0.01      0.533784  0.999087   0.897727  0.669492\n",
            "21       saga      l1    0.10      0.567568  0.999146   0.903226  0.697095\n",
            "22       saga      l1    1.00      0.560811  0.999134   0.902174  0.691667\n",
            "23       saga      l1   10.00      0.560811  0.999134   0.902174  0.691667\n",
            "24       saga      l1  100.00      0.560811  0.999134   0.902174  0.691667\n",
            "25       saga      l2    0.01      0.554054  0.999122   0.901099  0.686192\n",
            "26       saga      l2    0.10      0.560811  0.999134   0.902174  0.691667\n",
            "27       saga      l2    1.00      0.560811  0.999134   0.902174  0.691667\n",
            "28       saga      l2   10.00      0.560811  0.999134   0.902174  0.691667\n",
            "29       saga      l2  100.00      0.560811  0.999134   0.902174  0.691667\n"
          ]
        }
      ],
      "source": [
        "df=pd.DataFrame(li,columns=[\"Solver\",\"Penalty\",\"C\",\"Recall Score\",\"Accuracy\",\"Precision\",\"F1-Score\"])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CQwn-zkl9PkB"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsSiZMsdceAd"
      },
      "source": [
        "#RAMDOM FOREST\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "uCtxDBXFW6BV"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# random forest model creation\n",
        "rfc = RandomForestClassifier()\n",
        "rfc.fit(X_train_sampled, y_train_sampled)\n",
        "# predictions\n",
        "yPred = rfc.predict(X_test_sampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ClstkAkwPpM",
        "outputId": "e39d5646-4ae2-4d3e-8f52-8170335f0829"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16969    14]\n",
            " [   20 17115]]\n",
            "0.9990034585849112\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00     16983\n",
            "           1       1.00      1.00      1.00     17135\n",
            "\n",
            "    accuracy                           1.00     34118\n",
            "   macro avg       1.00      1.00      1.00     34118\n",
            "weighted avg       1.00      1.00      1.00     34118\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction = rfc.predict(X_test_sampled)\n",
        "print(confusion_matrix(y_test_sampled, prediction))\n",
        "print(accuracy_score(y_test_sampled, prediction))\n",
        "print(classification_report(y_test_sampled, prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "byBJ7AhxwZSD"
      },
      "source": [
        "#SUPPORT VECTOR MACHINES (SVM)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ol6s0cItwg57"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        " # \"Support vector classifier creation\"  \n",
        "classifier = SVC(kernel='sigmoid', random_state=0)  \n",
        "classifier.fit(X_train_sampled, y_train_sampled)\n",
        "# predictions\n",
        "yPred_SVC = classifier.predict(X_test_sampled)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ag-aVw-wU9nC",
        "outputId": "8b4fbd80-1b01-448c-93ba-6ef9ea37416d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SVC(kernel='sigmoid', random_state=0)"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        " \n",
        "classes = 4\n",
        "X,t= make_classification(100, 5, n_classes = classes, random_state= 40, n_informative = 2, n_clusters_per_class = 1)\n",
        "\n",
        "model = svm.SVC(kernel = 'sigmoid', random_state = 0, C=1.0)\n",
        "\n",
        "model.fit(X_train_sampled, y_train_sampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fTV7GB17xoDM",
        "outputId": "b9944631-9756-460c-81e9-ddf0e4318de2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[14776  2207]\n",
            " [ 2369 14766]]\n",
            "0.8658772495456943\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.87      0.87     16983\n",
            "           1       0.87      0.86      0.87     17135\n",
            "\n",
            "    accuracy                           0.87     34118\n",
            "   macro avg       0.87      0.87      0.87     34118\n",
            "weighted avg       0.87      0.87      0.87     34118\n",
            "\n"
          ]
        }
      ],
      "source": [
        "prediction = classifier.predict(X_test_sampled)\n",
        "print(confusion_matrix(y_test_sampled, prediction))\n",
        "print(accuracy_score(y_test_sampled, prediction))\n",
        "print(classification_report(y_test_sampled, prediction))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJWB-AfU1RDY"
      },
      "source": [
        "#Using GridsearchCV on SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJhwA52z1UUo",
        "outputId": "00cdf78d-843d-4e86-f6de-3a075404a3a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 5 folds for each of 25 candidates, totalling 125 fits\n",
            "[CV 1/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.894 total time=11.3min\n",
            "[CV 2/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.893 total time=10.9min\n",
            "[CV 3/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.893 total time=12.1min\n",
            "[CV 4/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.888 total time=11.8min\n",
            "[CV 5/5] END ........C=0.1, gamma=1, kernel=rbf;, score=0.895 total time=12.0min\n",
            "[CV 1/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.993 total time= 2.9min\n",
            "[CV 2/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.993 total time= 2.8min\n",
            "[CV 3/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.993 total time= 2.8min\n",
            "[CV 4/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.992 total time= 2.8min\n",
            "[CV 5/5] END ......C=0.1, gamma=0.1, kernel=rbf;, score=0.993 total time= 2.8min\n",
            "[CV 1/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.959 total time= 1.4min\n",
            "[CV 2/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.961 total time= 1.4min\n",
            "[CV 3/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.959 total time= 1.4min\n",
            "[CV 4/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.963 total time= 1.4min\n",
            "[CV 5/5] END .....C=0.1, gamma=0.01, kernel=rbf;, score=0.962 total time= 1.3min\n",
            "[CV 1/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.938 total time= 1.5min\n",
            "[CV 2/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.940 total time= 1.5min\n",
            "[CV 3/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.937 total time= 1.5min\n",
            "[CV 4/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.941 total time= 1.5min\n",
            "[CV 5/5] END ....C=0.1, gamma=0.001, kernel=rbf;, score=0.939 total time= 1.5min\n",
            "[CV 1/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.926 total time= 2.0min\n",
            "[CV 2/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.930 total time= 2.0min\n",
            "[CV 3/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.925 total time= 2.0min\n",
            "[CV 4/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.928 total time= 2.0min\n",
            "[CV 5/5] END ...C=0.1, gamma=0.0001, kernel=rbf;, score=0.928 total time= 2.0min\n",
            "[CV 1/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.995 total time=21.8min\n",
            "[CV 2/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.995 total time=23.6min\n",
            "[CV 3/5] END ..........C=1, gamma=1, kernel=rbf;, score=0.996 total time=21.8min\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "# defining parameter range\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000], \n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
        "              'kernel': ['rbf']} \n",
        "  \n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3)\n",
        "  \n",
        "# fitting the model for grid search\n",
        "grid.fit(X_train_sampled, y_train_sampled)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = .predict(X_test_sampled)\n",
        "print(confusion_matrix(y_test_sampled, prediction))\n",
        "print(accuracy_score(y_test_sampled, prediction))\n",
        "print(classification_report(y_test_sampled, prediction))"
      ],
      "metadata": {
        "id": "W0pywjypaccy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}